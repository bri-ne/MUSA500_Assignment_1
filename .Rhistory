Female7074 = B01001_046E,
Female7579 = B01001_047E,
Female8084 = B01001_048E,
Female85 = B01001_049E,
Median_Income = B06011_001E) %>%
mutate(Senior =   ( Male6566+
Male6769+
Male7074+
Male7579+
Male8084+
Male85+
Female6566+
Female6769+
Female7074+
Female7579+
Female8084+
Female85),
pctSenior = ifelse(TotalPop > 0, (Senior / TotalPop),0),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"),
seniorContext = ifelse(pctSenior> 0.25, "More Seniors\nThan Twice\nthe National Median", "Senior Population\nBelow the\nNational Median"))
boulder_tracts18_formap <-
get_acs(geography = "tract", variables = c( "B01001_001E",
"B01001_018E",
"B01001_019E",
"B01001_020E",
"B01001_021E",
"B01001_022E",
"B01001_023E",
"B01001_024E",
"B01001_025E",
"B01001_042E",
"B01001_043E",
"B01001_044E",
"B01001_045E",
"B01001_046E",
"B01001_047E",
"B01001_048E",
"B01001_049E",
"B06011_001E"),
year = 2018, state=08, county=013, geometry=T, output = "wide") %>%
st_transform('ESRI:102254')  %>%
rename(TotalPop = B01001_001E,
Male6061 = B01001_018E,
Male6264 = B01001_019E,
Male6566 = B01001_020E,
Male6769 = B01001_021E,
Male7074 = B01001_022E,
Male7579 = B01001_023E,
Male8084 = B01001_024E,
Male85 = B01001_025E,
Female6061 = B01001_042E,
Female6264 = B01001_043E,
Female6566 = B01001_044E,
Female6769 = B01001_045E,
Female7074 = B01001_046E,
Female7579 = B01001_047E,
Female8084 = B01001_048E,
Female85 = B01001_049E,
Median_Income = B06011_001E) %>%
mutate(Senior =   ( Male6566+
Male6769+
Male7074+
Male7579+
Male8084+
Male85+
Female6566+
Female6769+
Female7074+
Female7579+
Female8084+
Female85),
pctSenior = ifelse(TotalPop > 0, (Senior / TotalPop),0),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"),
seniorContext = ifelse(pctSenior> 0.25, "More Seniors Than\nthe National Average", "Fewer Seniors Than\nthe National Average"))
Senior.map<- ggplot() + geom_sf(data = na.omit(boulder_tracts18_formap), aes(fill =seniorContext)) +
scale_fill_manual(values = c("#b3cde3",  "#810f7c"), name="Senior Context") +
labs(title = "Senior Context") +
mapTheme() + theme(legend.position="bottom")
Income.map<- ggplot() + geom_sf(data = na.omit(boulder_tracts18_formap), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#b3cde3",  "#810f7c"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom")
censusContext.map<- plot_grid(Senior.map,
Income.map,
ncol = 2)
censusContext.map
boulder_tracts18_formap <-
get_acs(geography = "tract", variables = c( "B01001_001E",
"B01001_018E",
"B01001_019E",
"B01001_020E",
"B01001_021E",
"B01001_022E",
"B01001_023E",
"B01001_024E",
"B01001_025E",
"B01001_042E",
"B01001_043E",
"B01001_044E",
"B01001_045E",
"B01001_046E",
"B01001_047E",
"B01001_048E",
"B01001_049E",
"B06011_001E"),
year = 2018, state=08, county=013, geometry=T, output = "wide") %>%
st_transform('ESRI:102254')  %>%
rename(TotalPop = B01001_001E,
Male6061 = B01001_018E,
Male6264 = B01001_019E,
Male6566 = B01001_020E,
Male6769 = B01001_021E,
Male7074 = B01001_022E,
Male7579 = B01001_023E,
Male8084 = B01001_024E,
Male85 = B01001_025E,
Female6061 = B01001_042E,
Female6264 = B01001_043E,
Female6566 = B01001_044E,
Female6769 = B01001_045E,
Female7074 = B01001_046E,
Female7579 = B01001_047E,
Female8084 = B01001_048E,
Female85 = B01001_049E,
Median_Income = B06011_001E) %>%
mutate(Senior =   ( Male6566+
Male6769+
Male7074+
Male7579+
Male8084+
Male85+
Female6566+
Female6769+
Female7074+
Female7579+
Female8084+
Female85),
pctSenior = ifelse(TotalPop > 0, (Senior / TotalPop),0),
incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"),
seniorContext = ifelse(pctSenior> 0.22, "More Seniors Than\nthe National Average", "Fewer Seniors Than\nthe National Average"))
Senior.map<- ggplot() + geom_sf(data = na.omit(boulder_tracts18_formap), aes(fill =seniorContext)) +
scale_fill_manual(values = c("#b3cde3",  "#810f7c"), name="Senior Context") +
labs(title = "Senior Context") +
mapTheme() + theme(legend.position="bottom")
Income.map<- ggplot() + geom_sf(data = na.omit(boulder_tracts18_formap), aes(fill = incomeContext)) +
scale_fill_manual(values = c("#b3cde3",  "#810f7c"), name="Income Context") +
labs(title = "Income Context") +
mapTheme() + theme(legend.position="bottom")
censusContext.map<- plot_grid(Senior.map,
Income.map,
ncol = 2)
censusContext.map
income_resids.table<- st_join(pre_partion_with_geometry.sf.residuals, boulder_tracts18_formap) %>%
group_by(incomeContext) %>%
summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%
st_drop_geometry() %>%
kable(caption = "Test set MAPE by neighborhood income context")%>%kable_styling()
seniors_resids.table<- st_join(pre_partion_with_geometry.sf.residuals, boulder_tracts18_formap) %>%
group_by(seniorContext) %>%
summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%
st_drop_geometry() %>%
kable(caption = "Test set MAPE by neighborhood senior context")%>%kable_styling()
income_resids.table
income_resids.table+seniors_resids.table
seniors_resids.table
income_resids.table
# R. 4b
CV.MAEexp.hist
# R. 4a
reg.cv.table
maemape.table ## Deliverable ****************************************************
maemape.table <- maemape.df%>%kable(align=c('l', 'l')) %>%
kable_styling() %>% footnote(general_title = "\n",
general = "Table 3")
maemape.table ## Deliverable ****************************************************
# R. 4a
reg.cv.table
# R. 4b
CV.MAEexp.hist
# R. 4a
reg.cv.table
reg.cv$resample[1:5,]
reg.cv$resample[1:5,]
reg.cv.stats <- reg.cv$resample[1:5,]
reg.cv.stats <- reg.cv$resample
reg.cv..table <- reg.cv.stats %>%
kable(caption = "Coefficient-Level Estimates for a Model Fitted to\n Estimate Home Sale Price (LN) in Boulder Colorado.",
col.names = c("Predictor", "Estimator", "SE", "t", "p"),
digits = c(0, 2, 3, 2, 5),
align = c("l", "r", "r", "r", "r"))%>%
kable_styling()%>%
footnote(general_title = "\n",
general = "Table 4")
reg.cv.stats <- reg.cv$resample%>%tidy()
reg.cv.stats <- reg.cv$resample
reg.cv.stats <- reg.cv.stats%>%tidy()
####  Actually making the table ----
reg.cv.summary.table <- reg.cv_summary_renamed %>%
kable(caption = "Coefficient-Level Estimates for a Model Fitted to\n Estimate Home Sale Price (LN) in Boulder Colorado.",
col.names = c("Predictor", "Estimator", "SE", "t", "p"),
digits = c(0, 2, 3, 2, 5),
align = c("l", "r", "r", "r", "r"))%>%
kable_styling()%>%
footnote(general_title = "\n",
general = "Table 4")
knitr::opts_chunk$set()
#--- load libraries ----
library(tidyr)
library(dplyr)
library(DAAG)
library(car)  #to calculate VIF
library(MASS)
library(rsq)
library(kableExtra)
library(tidyverse) #for ggplot
library(sf) #for maps
library(cowplot) #for plotgrid
library(classInt)#for jenks breaks
library(rgdal)
library(ggplot2)
library(RColorBrewer)
#install.packages("broom") *NEW*
library(broom)
library(stargazer)
options(scipen=999)
#---- Step 1: Upload Data ----
ourdata <- read.csv("https://raw.githubusercontent.com/bri-ne/MUSA500_Assignment_1/main/RegressionData.csv")
summary(fit)
#Run regression model
#fit <- lm(MEDHVAL ~ LNBELPOV100 + PCTBACHMOR + PCTVACANT + PCTSINGLES, data=ourdata)
fit <- lm(LNMEDHVAL ~ LNBELPOV100 + PCTBACHMOR + PCTVACANT + PCTSINGLES, data=ourdata)
knitr::opts_chunk$set()
#--- load libraries ----
library(tidyr)
library(dplyr)
library(DAAG)
library(car)  #to calculate VIF
library(MASS)
library(rsq)
library(kableExtra)
library(tidyverse) #for ggplot
library(sf) #for maps
library(cowplot) #for plotgrid
library(classInt)#for jenks breaks
library(rgdal)
library(ggplot2)
library(RColorBrewer)
#install.packages("broom") *NEW*
library(broom)
library(stargazer)
options(scipen=999)
#---- Step 1: Upload Data ----
ourdata <- read.csv("https://raw.githubusercontent.com/bri-ne/MUSA500_Assignment_1/main/RegressionData.csv")
#### THIS FIRST CHUNK INCLUDES CODE FOR THE SUMMARY STATISTICS AND THE HISTOGRAMS ####
#save the summary to a df (i have 0 idea how this code works, just a copy paste from the web)
#we really only need the mean and sd, so I will clean this up
summary <-as.data.frame(apply(ourdata,2,summary))
#checking the index
base::row(summary,1)
#dropping all rows except the mean
summary<-summary[-c(1,2,3,5,6),]
#transposing so variables (mean and sd) are columns
summary <- summary%>%base::t()%>%as.data.frame()
#getting sd and adding sd column
sdMedV <- sd(ourdata$MEDHVAL)
sdBach <- sd(ourdata$PCTBACHMOR)
sdNbel <- sd(ourdata$NBELPOV100)
sdVac <- sd(ourdata$PCTVACANT)
sdSing <- sd(ourdata$PCTSINGLES)
sdMedHHINC <- sd(ourdata$MEDHHINC)
sdcol <- list(0, 0, sdMedV, sdBach, sdMedHHINC, sdVac, sdSing, sdNbel)
summary$sd <- sdcol
#dropping the other things we don't need
base::row(summary,1)
summary<- summary[-c(1,2,5),]
summary<- summary%>%as.data.frame()
summary
#create a copy of the summary table to give it nicer row names for the table below
summary_nice_names <- summary
rownames(summary_nice_names) <- c("Median House Value",
"% of Indviduals with Bachelor's Degrees or Higher",
'% of Vacant Houses',
"% of Single House Units",
"% Households Living in Poverty")
#final summary stats table
summary_table <- kable(summary_nice_names) %>%
kable_styling() %>%
footnote(general_title = "Summary Statistics\n",
general = "Table 1")
#---- Step 1A.ii: Histograms ----
#check them out, regular histogram
hists <- histogram( ~ MEDHVAL +PCTBACHMOR +NBELPOV100 +PCTSINGLES +PCTVACANT, layout=c(2,3), data = ourdata, main='Distribution of Raw Variables', sub= 'Figure 1', col="#8C96C6", breaks = 50, scales='free')
#none look normal so we will examine if a log transformation will make them normal
#remember to use 1+ if any variable has zero values
#the only variable that does not have a 0 value is MEDHVAL
ourdata$LNMEDHVAL <- log(ourdata$MEDHVAL)
ourdata$LNPCTBACHMOR <- log(1+ourdata$PCTBACHMOR)
ourdata$LNBELPOV100 <- log(1+ourdata$NBELPOV100)
ourdata$LNPCTVACANT <- log(1+ourdata$PCTVACANT)
ourdata$LNPCTSINGLES <- log(1+ourdata$PCTSINGLES)
#### Logged
LNhists <- histogram( ~ LNMEDHVAL +LNPCTBACHMOR +LNBELPOV100 +LNPCTSINGLES +LNPCTVACANT,layout=c(2,3),data = ourdata,
main='Distribution of Natural Log of Variables', sub= 'Figure 2', col="#B3CDE3", breaks = 50, scales='free')
summary_table
hists
LNhists
#### THIS CHUNK INCLUDE SCATTER PLOT CODE ####
#---- Step 1B: Variable Scatter Plots ----
#investigate to see if our predictors relationship with the dependent variable
# is linear by plotting as scatter plots
pLNBelpov <- ggplot(ourdata, aes(x = LNMEDHVAL, y= LNBELPOV100))+
geom_point(size=2.5, color = "#4D004B", alpha = 0.5)+theme_minimal()
pBach <- ggplot(ourdata, aes(x = LNMEDHVAL, y= PCTBACHMOR))+
geom_point(size=2.5, color = "#4D004B", alpha = 0.5)+theme_minimal()
pVac <- ggplot(ourdata, aes(x = LNMEDHVAL, y= PCTVACANT))+
geom_point(size=2.5, color = "#4D004B", alpha = 0.5)+theme_minimal()
pSing <- ggplot(ourdata, aes(x = LNMEDHVAL, y= PCTSINGLES))+
geom_point(size=2.5, color = "#4D004B", alpha = 0.5)+theme_minimal()+labs(caption="Figure 3")
scattergrid <- plot_grid(
pLNBelpov,
pBach,
pVac,
pSing,
labels = c("% Below Poverty (LN)",
"Bachelors Degree",
"% Vacant Homes",
"% Single House Units"),
label_size = 11,
label_x =-.1,
label_y = 1.03,
scale= 0.9,
align = 'hv',
ncol = 2, nrow = 2)
scattergrid
#### THIS CHUNK INCLUDE CORR CODE AND OUTPUT
#---- Step 1C: Pearson Correlations ----
#make new df that just has our predictors and dependent variable
pred_var <- ourdata%>%dplyr::select(LNMEDHVAL, LNBELPOV100, PCTBACHMOR, PCTSINGLES, PCTVACANT)
pcorr <- cor(pred_var, method="pearson")
#Observe that there isnt severe multicollinearity (i.e., no correlations where
# r>.8 or r<-.8), so we can include all four predictors in the regression.
#*********matrix for markdown*****************************************
pcorr <- pcorr%>%kable(digits = c(4, 4, 4, 4, 4),
align = c("l", "r", "r", "r", "r"))%>%kable_styling()%>%footnote(general_title = "Pearson's Correlation of Predictors",
general = "Table 1")
pcorr
#### THIS CHUNK INCLUDES THE MAPPING & JENKS CODE ###
#---- Step 2A: Open Regression_Data shapefile (or GeoJSON in our case)----
#shapefiles are really hard to work with without having to download and mess with working directories in the code
#SO i converted the shapefile to a GeoJSON and will use that instead
ourdata_geom <- st_read("https://raw.githubusercontent.com/bri-ne/MUSA500_Assignment_1/main/RegressionData.geojson")
#getting Jenks Breaks for LNMEDHVAL
classes <- classIntervals(ourdata_geom$LNMEDHVAL, n = 5, style = "jenks")
classes$brks
#we'll create a new column in our sf object using the base R cut() function to cut up our percent variable into distinct groups.
ourdata_geom <- ourdata_geom %>%
mutate(LNMEDVHAL_class = cut(LNMEDHVAL, classes$brks, include.lowest = T))
#mapping
choro_LNMEDHVAL <- ggplot() +
geom_sf(data = ourdata_geom,
aes(fill = LNMEDVHAL_class),
alpha = 1,
colour = "gray80",
size = 0.15) +
scale_fill_brewer(palette = "PuBu",
name = "LN Median House Value") +
labs(x = NULL, y = NULL,
title = "LN Median House Value in Philadelphia by Block Group",
subtitle = "Source: U.S. Census",
caption = "Map 1") +
theme(line = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
panel.background = element_blank())
#making remaining JENKS for maps --------------------
#PctVacant Jenks
PVclasses <- classIntervals(ourdata_geom$PCTVACANT, n = 5, style = "jenks")
PVclasses$brks
ourdata_geom <- ourdata_geom %>%
mutate(PCTVACANT_class = cut(PCTVACANT, PVclasses$brks, include.lowest = T))
#PctSingle Jenks
PSclasses <- classIntervals(ourdata_geom$PCTSINGLES, n = 5, style = "jenks")
PSclasses$brks
ourdata_geom <- ourdata_geom %>%
mutate(PCTSINGLES_class = cut(PCTSINGLES, PSclasses$brks, include.lowest = T))
#PctBach Jenks
PBclasses <- classIntervals(ourdata_geom$PCTBACHMOR, n = 5, style = "jenks")
PBclasses$brks
ourdata_geom <- ourdata_geom %>%
mutate(PCTBACHMOR_class = cut(PCTBACHMOR, PBclasses$brks, include.lowest = T))
#LNBelPov Jenks
BPclasses <- classIntervals(ourdata_geom$LNNBELPOV, n = 3, style = "jenks")
BPclasses$brks
ourdata_geom <- ourdata_geom %>%
mutate(LNNBELPOV_class = cut(LNNBELPOV, BPclasses$brks, include.lowest = T))
#mapping the rest --------------------------------------
#PctVacant Map
choro_PctVac <- ggplot() +
geom_sf(data = ourdata_geom,
aes(fill = PCTVACANT_class),
#alpha = 1,
colour = NA) +
scale_fill_brewer(palette = "PuBu",
name = "Percent Houses Vacant") +
labs(x = NULL, y = NULL,
subtitle = "Perecent of Vacant Houses\nin Philadelphia by Block Group") +
theme(line = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
panel.background = element_blank())
#PctSing Map
choro_PctSing <- ggplot() +
geom_sf(data = ourdata_geom,
aes(fill = PCTSINGLES_class),
#alpha = 1,
colour = NA) +
scale_fill_brewer(palette = "PuBu",
name = "Percent Single House Units") +
labs(x = NULL, y = NULL,
subtitle = "Perecent of Single House Units\nin Philadelphia by Block Group") +
theme(line = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
panel.background = element_blank())
#PctBach Map
choro_PctBach <- ggplot() +
geom_sf(data = ourdata_geom,
aes(fill = PCTBACHMOR_class),
#alpha = 1,
colour = NA) +
scale_fill_brewer(palette = "PuBu",
name = "Percent Bachelors Degree") +
labs(x = NULL, y = NULL,
subtitle = "Percent of Individuals with a Bachelors\nDegree or Higher in Philadelphia\nby Block Group") +
theme(line = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
panel.background = element_blank())
#LNBelPov Map
choro_LNBelPov <- ggplot() +
geom_sf(data = ourdata_geom,
aes(fill = LNNBELPOV_class),
#alpha = 1,
colour = NA) +
scale_fill_brewer(palette = "PuBu",
name = "LN Percent Households\nin Poverty") +
labs(x = NULL, y = NULL,
subtitle = "LN Percent of Households Living\nin Poverty in Philadelphia\nby Block Group",
caption = "Map 2. Source: U.S. Census") +
theme(line = element_blank(),
axis.text = element_blank(),
axis.title = element_blank(),
panel.background = element_blank())
#--- Unfortunately I had to do three breaks b/c the values for the LN %BELPOV were not varied enough
mapgrid <- plot_grid( choro_PctVac,
choro_PctSing,
choro_PctBach,
choro_LNBelPov,
align = c("hv","hv","hv","hv"),
ncol = 2, nrow = 2)
choro_LNMEDHVAL
mapgrid
#---- Step 3 : Regression Analysis -------
#Run regression model
#fit <- lm(MEDHVAL ~ LNBELPOV100 + PCTBACHMOR + PCTVACANT + PCTSINGLES, data=ourdata)
fit <- lm(LNMEDHVAL ~ LNBELPOV100 + PCTBACHMOR + PCTVACANT + PCTSINGLES, data=ourdata)
summary(fit)
#3A
fit.summary<- broom::tidy(fit)%>%kable(
align = c("l", "r", "r", "r", "r"))%>%kable_styling()%>%footnote(general_title = "Regression Summary",
general = "Table 2")
#Summary of Regression
#all predictors are significant - p value < 0.05
#R squared - 55.38% = % of variance in median house value explained
#by predictors
#Adjusted R Squared - 55.28% = % of variance in median house value explained
#BY predictors adjusted for the number of predictors
#P value associated with F-ratio of 532 is less than 0.0001 -
#We can reject the H0 that all Beta coefficients for the predictors are 0
#3B
anova.fit<- broom::tidy(anova(fit))%>%kable(digits = c(0, 4, 4, 4, 4),
align = c("l", "r", "r", "r", "r", "r"))%>%kable_styling()%>%footnote(general_title = "ANOVA",
general = "Table 3")
#ANOVA table containing SSE and SSR
#SSR = SS(LNBELPOV100) + SS(PCTBACHMOR) +SS(PCTVACANTS) + SS(PCTSINGLES) =
# 869866100108 + 2345334804156 +  58030777316 + 154801231763 = 3428032913343
# Amount of total variance in Median House value explained by model
#SSE = 2761620505240 = amount of total variance in median house value that is
# unexplained by the model
#3C
#new column saving predicted values
ourdata$predvals <- fitted(fit)
#new column saving residuals
ourdata$resids <- residuals(fit)
#New column saving standardized residuals
ourdata$stdres <- rstandard(fit)
#3D Create a scatterplot with standardized residuals on Y axis and
# Predicted Values on x axis.
ResidualPlot<- ggplot(ourdata, aes(x = predvals, y= stdres))+
geom_point(size=1.5, color = 'darkslateblue', alpha = .5)+
geom_hline(yintercept=0, size = .5)+
labs(x = 'Predicted LN Median House Value',
y = 'Standardized Residuals',
caption = 'Figure 4')
fit.summary
anova.fit
ResidualPlot
summary(fit)
summary(fit)
summary(fit)
fit <- lm(LNMEDHVAL ~ LNBELPOV100 + PCTBACHMOR + PCTVACANT + PCTSINGLES, data=ourdata)
summary(fit)
